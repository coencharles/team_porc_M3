{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] milestone 3: spectral graph theory\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018\n",
    "\n",
    "[Michaël Defferrard](http://deff.ch), [EPFL LTS2](https://lts2.epfl.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: `<34>`\n",
    "* Students: `<Valentin Morel, Xavier Sieber, Cédric Schumacher, Charles-Théophile Coen>`\n",
    "* Dataset: `<Terrorist attack>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "* Milestones have to be completed by teams. No collaboration between teams is allowed.\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart & Run All\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this milestone is to get familiar with the graph Laplacian and its spectral decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Load your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a `No module named 'sklearn'` error when running the below cell, install [scikit-learn](https://scikit-learn.org) with `conda install scikit-learn` (after activating the `ntds_2018` environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's denote your graph as $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E}, A)$, where $\\mathcal{V}$ is the set of nodes, $\\mathcal{E}$ is the set of edges, $A \\in \\mathbb{R}^{N \\times N}$ is the (weighted) adjacency matrix, and $N = |\\mathcal{V}|$ is the number of nodes.\n",
    "\n",
    "Import the adjacency matrix $A$ that you constructed in the first milestone.\n",
    "(You're allowed to update it between milestones if you want to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = np.load('Adjacency1.npy') # Your code here.\n",
    "\n",
    "# Suppression of the nodes with 0 degree (otherwise problem when computing the normalized Laplacian)\n",
    "degree = adjacency.sum(axis=0)\n",
    "list_to_delete = []; # This array is going to contain all the index of the nodes with degree 0\n",
    "\n",
    "for i in range(0,len(adjacency)):\n",
    "    degree_node_i = degree.item(i)\n",
    "    \n",
    "    if degree_node_i == 0:\n",
    "        list_to_delete.append(i)\n",
    "        \n",
    "list_to_delete = np.array(list_to_delete)\n",
    "\n",
    "for j in range(0,len(list_to_delete)): \n",
    "    index = list_to_delete[j]\n",
    "    adjacency = np.delete(adjacency, index, axis=0)\n",
    "    adjacency = np.delete(adjacency, index, axis=1)\n",
    "    list_to_delete = list_to_delete - 1 \n",
    "\n",
    "degree = adjacency.sum(axis=0)\n",
    "n_nodes = len(adjacency) # Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Graph Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "From the (weighted) adjacency matrix $A$, compute both the combinatorial (also called unnormalized) and the normalized graph Laplacian matrices.\n",
    "\n",
    "Note: if your graph is weighted, use the weighted adjacency matrix. If not, use the binary adjacency matrix.\n",
    "\n",
    "For efficient storage and computation, store these sparse matrices in a [compressed sparse row (CSR) format](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR.2C_CRS_or_Yale_format.29)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = sparse.csr_matrix(adjacency) # Transformation of the adjacency matrix to a CSR matrix\n",
    "\n",
    "D = sparse.diags(degree) # Degree matrix\n",
    "D2 = sparse.diags(1/np.sqrt(degree)) # Represent D^(-1/2)\n",
    "\n",
    "laplacian_combinatorial = D - adjacency # Your code here.\n",
    "laplacian_normalized =  D2.dot(laplacian_combinatorial.dot(D2)) # Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one of them as the graph Laplacian $L$ for the rest of the milestone.\n",
    "We however encourage you to run the code with both to get a sense of the difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian =  laplacian_combinatorial # Either laplacian_combinatorial or laplacian_normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Compute the eigendecomposition of the Laplacian $L = U^\\top \\Lambda U$, where the columns $u_k \\in \\mathbb{R}^N$ of $U = [u_1, \\dots, u_N] \\in \\mathbb{R}^{N \\times N}$ are the eigenvectors and the diagonal elements $\\lambda_k = \\Lambda_{kk}$ are the corresponding eigenvalues.\n",
    "\n",
    "Make sure that the eigenvalues are ordered, i.e., $0 = \\lambda_1 \\leq \\lambda_2 \\leq \\dots \\leq \\lambda_N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate eigendecomposition\n",
    "values, vectors = np.linalg.eigh(laplacian.toarray())\n",
    "\n",
    "eigenvectors = vectors # Your code here.\n",
    "eigenvalues = np.round(np.absolute(values),2) # Your code here.\n",
    "\n",
    "assert eigenvectors.shape == (n_nodes, n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justify your choice of eigensolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "'''\n",
    "Dépend de notre matrice L si elle est réelle np suddit je pense. mais avec sparse on peut choisir le nomvre de vect. propre désiré\n",
    "'''\n",
    "\n",
    "As our laplacian matrix is a sparse matrix, it would be logical to use the function sparse.linalg.eigs() in order to find the eigen decomposition. Unfortunately, with this function, we can only get N-1 eigenvalues. Thus, in order to find all the eigenvalues of the laplacian, we transformed our matrix to a np.ndarray in order to use the function np.linalg.eigh(), which gives us the complete decomposition for a Hermitian matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "We can write $L = S S^\\top$. What is the matrix $S$? What does $S^\\top x$, with $x \\in \\mathbb{R}^N$, compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "$S$ is the incidence matrix. It takes as input a node ($n_i$) and an edge ($e_j$). For directed graph we have:\n",
    "* If the edge $e_j$ is going from $n_i$ to $n_k$, the value $S[i,j]$ of the matrix is going to be 1 \n",
    "* If the edge $e_j$ is going from $n_k$ to $n_i$, the value $S[i,j]$ of the matrix is going to be -1 \n",
    "* If the edge $e_j$ is not related to $n_i$, the value $S[i,j]$ of the matrix is going to be 0\n",
    "\n",
    "For undirected graph, if the edge $e_j$ is going from $n_i$ to $n_k$ or the other way around, the value $S[i,j]$ of the matrix is going to be 1.\n",
    "\n",
    "Each row of the $S^\\top$ matrix is going to have two values only: a $+1$ at the node corresponding to the head of the edge, and a $-1$ at the node corresponding to the tail of the edge. The vector $x$ attributes a values for each node, and therefore, the product $S^\\top x$ represents the difference between the two numbers given to the two nodes of an edge. This is correct for directed graph.\n",
    "\n",
    "For undirected graph, the product $S^\\top x$ represents the addition of the two numbers given to the nodes of an edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Show that $\\lambda_k = \\| S^\\top u_k \\|_2^2$, where $\\| \\cdot \\|_2^2$ denotes the squared Euclidean norm (a.k.a. squared $L^2$ norm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "PAS COMPLET peut-être début de la résolution dans chapitre Laplacian Eigenmaps slide 9, mais pas sûr\n",
    "\n",
    "$u_k^\\top \\lambda_k = u_k^\\top L u_k = u_k^\\top S S^\\top u_k = \\| S^\\top u_k \\|_2^2 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the quantity $\\| S^\\top x \\|_2^2$ tell us about $x$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "The quantity $\\| S^\\top x \\|_2^2$ tell us the difference, or derivative, of the vector $x$ along all the edges of our graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "What is the value of $u_0$, both for the combinatorial and normalized Laplacians?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your annswer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Look at the spectrum of the Laplacian by plotting the eigenvalues.\n",
    "Comment on what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25, 5))\n",
    "for i in range(0, len(eigenvalues)):\n",
    "    plt.bar(i,eigenvalues[i], width=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "An interesting part of the spectrum that we can see on both Laplacian, is the eigenvalues equal to 0. For both, the combinatorial and normalized Laplacian, we have 139 eigenvalues equal to 0. From the theory, we know that the multiplicity of the eivenvalue 0 is equal to the number of connected components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many connected components are there in your graph? Answer using the eigenvalues only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connected componenets equal to 139\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "number_connected_components = len(eigenvalues)- np.count_nonzero(eigenvalues)\n",
    "\n",
    "print('Number of connected componenets equal to', number_connected_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there an upper bound on the eigenvalues, i.e., what is the largest possible eigenvalue? Answer for both the combinatorial and normalized Laplacians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "\n",
    "For the combinatorial Laplacian, there are no theoretical largest value for the engienvalue. However, we saw in the theory that the normalized Laplacian is bound to an upper value equal to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Laplacian eigenmaps\n",
    "\n",
    "*Laplacian eigenmaps* is a method to embed a graph $\\mathcal{G}$ in a $d$-dimensional Euclidean space.\n",
    "That is, it associates a vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$.\n",
    "The graph $\\mathcal{G}$ is thus embedded as $Z \\in \\mathbb{R}^{N \\times d}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What do we use Laplacian eigenmaps for? (Or more generally, graph embeddings.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**\n",
    "'''\n",
    "Laplacian eigenmaps are used for nonlinear dimensionality reduction. \n",
    "Traditional techniques like PCA don't consider the intrinsic geometry of the data.\n",
    "So Laplacian eigenmaps builds a graph from neighborhood information of the data set. Each data point serves as a node on the graph and connectivity between nodes is governed by the proximity of neighboring points (using e.g. the k-nearest neighbor algorithm). The graph thus generated can be considered as a discrete approximation of the low-dimensional manifold in the high-dimensional space.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Embed your graph in $d=2$ dimensions with Laplacian eigenmaps.\n",
    "Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "\n",
    "**Recompute** the eigenvectors you need with a partial eigendecomposition method for sparse matrices.\n",
    "When $k \\ll N$ eigenvectors are needed, partial eigendecompositions are much more efficient than complete eigendecompositions.\n",
    "A partial eigendecomposition scales as $\\Omega(k |\\mathcal{E}|$), while a complete eigendecomposition costs $\\mathcal{O}(N^3)$ operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n",
    "val, vect = sparse.linalg.eigsh(laplacian, k = number_connected_components, which = 'SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_components(adjacency):\n",
    "    \"\"\"Find the connected components of a graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency: numpy array\n",
    "        The (weighted) adjacency matrix of a graph.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of numpy arrays\n",
    "        A list of adjacency matrices, one per connected component.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here.\n",
    "    components=[]\n",
    "    size= len(adjacency)\n",
    "    meta_nodecheck=np.zeros(size) #array that contains which connected component have been checked: \n",
    "                                    #if node[i] = 1, it means that the connected component containing node[i] \n",
    "                                        #has been checked and assesed\n",
    "            \n",
    "    comp_m = np.zeros(size) #matrix where each row corresponds to a connected component\n",
    "    next_node=0\n",
    "    \n",
    "    while comp_m.sum() != size:\n",
    "    \n",
    "        nodes_reach = np.zeros(size)\n",
    "        nodes_checked = np.zeros(size)\n",
    "\n",
    "        nodes_reach[next_node]=1\n",
    "        direc=np.subtract(nodes_reach,nodes_checked)\n",
    "\n",
    "        while direc.sum() != 0:\n",
    "            for idx in range(0,size):\n",
    "                if direc[idx]:\n",
    "                    for line_idx in range(0,size):\n",
    "                        if adjacency[idx,line_idx]:\n",
    "                            nodes_reach[line_idx]=1\n",
    "                    nodes_checked[idx]=1\n",
    "            direc=np.subtract(nodes_reach,nodes_checked)\n",
    "        \n",
    "        comp_m=np.vstack((comp_m,nodes_reach)) #the nodes_reach represent all the nodes of a connected component;\n",
    "                                                #we add this array to the matrix containing all the connected components\n",
    "        meta_nodecheck=np.add(meta_nodecheck,nodes_reach)\n",
    "        \n",
    "        n=0\n",
    "        for value in meta_nodecheck:\n",
    "            if value==0:\n",
    "                next_node=n\n",
    "                break\n",
    "            n+=1\n",
    "    comp_m=np.delete(comp_m,0,axis=0)\n",
    "    \n",
    "    for row in comp_m:\n",
    "        index_v=[0];  \n",
    "        n=0;\n",
    "        for value in row:\n",
    "            if value!=0:\n",
    "                index_v=np.hstack((index_v,n)) #create an array of each connected component with the index of each node\n",
    "            n+=1\n",
    "        index_v=np.delete(index_v,0,axis=0)\n",
    "        adj=adjacency[index_v,:][:,index_v]\n",
    "        components.append(adj)\n",
    "    \n",
    "    \n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the 106 features \n",
    "features = pd.read_csv('TerrorAttack/terrorist_attack.nodes',delim_whitespace=' ',header = None,engine='python')\n",
    "features = features.drop( columns=0)\n",
    "features = features.drop(columns=107)\n",
    "X = features\n",
    "\n",
    "# Creation of the adjacency matrix for the Laplacian Eigenmaps corresponding to the distance\n",
    "distances = pdist(X.values, metric='euclidean')\n",
    "kernel_width = distances.mean()\n",
    "weights = np.exp(-distances**2 / kernel_width**2)\n",
    "adjacency_eigen = squareform(weights)\n",
    "adjacency_eigen[adjacency_eigen < np.mean(weights)] = 0\n",
    "\n",
    "# Suppression of the nodes with 0 degree (otherwise problem when computing the normalized Laplacian)\n",
    "degree_eigen = adjacency_eigen.sum(axis=0)\n",
    "list_to_delete_eigen = []; # This array is going to contain all the index of the nodes with degree 0\n",
    "\n",
    "for i in range(0,len(adjacency_eigen)):\n",
    "    degree_node_i = degree_eigen.item(i)\n",
    "    \n",
    "    if degree_node_i == 0:\n",
    "        list_to_delete_eigen.append(i)\n",
    "        \n",
    "list_to_delete_eigen = np.array(list_to_delete_eigen)\n",
    "\n",
    "for j in range(0,len(list_to_delete_eigen)): \n",
    "    index = list_to_delete_eigen[j]\n",
    "    adjacency_eigen = np.delete(adjacency_eigen, index, axis=0)\n",
    "    adjacency_eigen = np.delete(adjacency_eigen, index, axis=1)\n",
    "    list_to_delete_eigen = list_to_delete_eigen - 1 \n",
    "\n",
    "degree_eigen = adjacency_eigen.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_eigen = sparse.csr_matrix(adjacency_eigen)\n",
    "\n",
    "D_eigen = sparse.diags(degree_eigen) # Degree matrix\n",
    "D2_eigen = sparse.diags(1/np.sqrt(degree_eigen)) # Represent D^(-1/2)\n",
    "\n",
    "laplacian_combinatorial_eigen = D_eigen - adjacency_eigen # Your code here.\n",
    "laplacian_normalized_eigen =  D2_eigen.dot(laplacian_combinatorial_eigen.dot(D2_eigen)) # Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the nodes embedded in 2D. Comment on what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian_eigen = laplacian_combinatorial_eigen\n",
    "val, vect = sparse.linalg.eigsh(laplacian_eigen, k = 10, which = 'SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_components = find_components(adjacency_eigen.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_components:\n",
    "    list_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the embedding $Z \\in \\mathbb{R}^{N \\times d}$ preserve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Spectral clustering\n",
    "\n",
    "*Spectral clustering* is a method to partition a graph into distinct clusters.\n",
    "The method associates a feature vector $z_i \\in \\mathbb{R}^d$ to every node $v_i \\in \\mathcal{V}$, then runs [$k$-means](https://en.wikipedia.org/wiki/K-means_clustering) in the embedding space $\\mathbb{R}^d$ to assign each node $v_i \\in \\mathcal{V}$ to a cluster $c_j \\in \\mathcal{C}$, where $k = |\\mathcal{C}|$ is the number of desired clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Choose $k$ and $d$. How did you get to those numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "1. Embed your graph in $\\mathbb{R}^d$ as $Z \\in \\mathbb{R}^{N \\times d}$.\n",
    "   Try with and without re-normalizing the eigenvectors by the degrees, then keep the one your prefer.\n",
    "1. If you want $k=2$ clusters, partition with the Fiedler vector. For $k > 2$ clusters, run $k$-means on $Z$. Don't implement $k$-means, use the `KMeans` class imported from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "Use the computed cluster assignment to reorder the adjacency matrix $A$.\n",
    "What do you expect? What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "\n",
    "If you have ground truth clusters for your dataset, compare the cluster assignment from spectral clustering to the ground truth.\n",
    "A simple quantitative measure is to compute the percentage of nodes that have been correctly categorized.\n",
    "If you don't have a ground truth, qualitatively assess the quality of the clustering.\n",
    "\n",
    "Ground truth clusters are the \"real clusters\".\n",
    "For example, the genre of musical tracks in FMA, the category of Wikipedia articles, the spammer status of individuals, etc.\n",
    "Look for the `labels` in the [dataset descriptions](https://github.com/mdeff/ntds_2018/tree/master/projects/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "\n",
    "Plot the cluster assignment (one color per cluster) on the 2D embedding you computed above with Laplacian eigenmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Why did we use the eigenvectors of the graph Laplacian as features? Could we use other features for clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
